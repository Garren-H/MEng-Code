{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cmdstanpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "sys.path.insert(0, '/home/garren/Documents/MEng/Code/Latest_results/HPC Files/Hybrid PMF')\n",
    "sys.path.insert(0, '/home/garren/Documents/MEng/Code/Latest_results/HPC Files')\n",
    "\n",
    "from Post_procs import PostProcess\n",
    "from All_code import subsets\n",
    "import os \n",
    "\n",
    "from IPython.display import clear_output\n",
    "from matplotlib.lines import Line2D\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "functional_groups = np.array(['all'])\n",
    "variance_known = True\n",
    "inf_type = 'MAP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtain variables of interest for data without clusters \n",
    "post_obj = PostProcess(functional_groups=functional_groups, \n",
    "                       include_clusters=False, \n",
    "                       variance_known=variance_known, \n",
    "                       inf_type=inf_type)\n",
    "\n",
    "data_dict_c_0 = post_obj.get_MC()\n",
    "rec_dict_c_0 = post_obj.get_reconstructed_errors()\n",
    "err_metrics_c_0 = post_obj.compute_error_metrics(data_dict=data_dict_c_0, is_testing=True)\n",
    "rec_err_metrics_c_0 = post_obj.compute_error_metrics(data_dict=rec_dict_c_0, is_testing=False)\n",
    "A_c_0 = post_obj.get_pred_param_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Obtain variables of interest for data with clusters\n",
    "post_obj = PostProcess(functional_groups=functional_groups, \n",
    "                       include_clusters=True, \n",
    "                       variance_known=variance_known, \n",
    "                       inf_type=inf_type)\n",
    "\n",
    "data_dict_c_1 = post_obj.get_MC()\n",
    "rec_dict_c_1 = post_obj.get_reconstructed_errors()\n",
    "err_metrics_c_1 = post_obj.compute_error_metrics(data_dict=data_dict_c_1, is_testing=True)\n",
    "rec_err_metrics_c_1 = post_obj.compute_error_metrics(data_dict=rec_dict_c_1, is_testing=False)\n",
    "A_c_1 = post_obj.get_pred_param_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the training error distributions for the two cases\n",
    "bins = 50\n",
    "er_MC_c_0 = np.abs(data_dict_c_0['y_MC'] - data_dict_c_0['y_exp'])\n",
    "er_MC_c_1 = np.abs(data_dict_c_1['y_MC'] - data_dict_c_1['y_exp'])\n",
    "er_UNIFAC = np.abs(data_dict_c_0['y_UNIFAC'] - data_dict_c_0['y_exp'])\n",
    "min_val = 0\n",
    "max_val = 1000\n",
    "\n",
    "bin_edges = np.linspace(min_val, max_val, bins + 1)\n",
    "bin_edges = np.append(bin_edges, max_val + bin_edges[1] - bin_edges[0])\n",
    "\n",
    "er_MC_c_0[er_MC_c_0 > bin_edges[-1]] = bin_edges[-1]\n",
    "er_MC_c_1[er_MC_c_1 > bin_edges[-1]] = bin_edges[-1]\n",
    "er_UNIFAC[er_UNIFAC > bin_edges[-1]] = bin_edges[-1]\n",
    "\n",
    "fig, ax = plt.subplots(2, figsize=(10, 10))\n",
    "\n",
    "path = '/home/garren/Documents/MEng/Code/Latest_results/HPC Files/Hybrid PMF/Subsets/all/Error_plots/Testing'\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Plot histograms with the same bin edges\n",
    "ax[0].hist(er_MC_c_0, bins=bin_edges, color='b', alpha=0.5, label='MC - No clusters')\n",
    "ax[0].hist(er_MC_c_1, bins=bin_edges, color='r', alpha=0.5, label='MC - With clusters')\n",
    "ax[0].hist(er_UNIFAC, bins=bin_edges, color='g', alpha=0.5, label='UNIFAC')\n",
    "ax[0].legend(loc='upper right', bbox_to_anchor=(1.3, 1))\n",
    "ax[0].set_ylabel('Frequency')\n",
    "ax[0].set_xlabel('Absolute error')\n",
    "ax[0].set_xticks(ticks=[0, 200, 400, 600, 800, 1000], labels=['0', '200', '400', '600', '800', '1000+'])\n",
    "\n",
    "ax[1].plot(data_dict_c_0['y_MC'], data_dict_c_0['y_exp'], '.b', label='MC - No clusters', alpha=0.5)\n",
    "ax[1].plot(data_dict_c_1['y_MC'], data_dict_c_1['y_exp'], '.r', label='MC - With clusters', alpha=0.5)\n",
    "ax[1].plot(data_dict_c_0['y_UNIFAC'], data_dict_c_0['y_exp'], '.g', label='UNIFAC', alpha=0.5)\n",
    "ax[1].legend(loc='upper right', bbox_to_anchor=(1.3, 1))\n",
    "ax[1].set_ylabel('Experimental')\n",
    "ax[1].set_xlabel('Predicted')\n",
    "max_lim = max(max(data_dict_c_0['y_exp']), max(data_dict_c_0['y_MC']), max(data_dict_c_1['y_MC']), max(data_dict_c_0['y_UNIFAC']))\n",
    "min_lim = min(min(data_dict_c_0['y_exp']), min(data_dict_c_0['y_MC']), min(data_dict_c_1['y_MC']), min(data_dict_c_0['y_UNIFAC']))\n",
    "ax[1].plot([min_lim, max_lim], [min_lim, max_lim], 'k--')\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(f'{path}/Err_dist.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the training error distributions for the two cases\n",
    "bins = 50\n",
    "er_MC_c_0 = np.abs(rec_dict_c_0['y_MC'] - rec_dict_c_0['y_exp'])\n",
    "er_MC_c_1 = np.abs(rec_dict_c_1['y_MC'] - rec_dict_c_1['y_exp'])\n",
    "er_UNIFAC = np.abs(rec_dict_c_0['y_UNIFAC'] - rec_dict_c_0['y_exp'])\n",
    "min_val = 0\n",
    "max_val = 1000\n",
    "\n",
    "bin_edges = np.linspace(min_val, max_val, bins + 1)\n",
    "bin_edges = np.append(bin_edges, max_val + bin_edges[1] - bin_edges[0])\n",
    "\n",
    "er_MC_c_0[er_MC_c_0 > bin_edges[-1]] = bin_edges[-1]\n",
    "er_MC_c_1[er_MC_c_1 > bin_edges[-1]] = bin_edges[-1]\n",
    "er_UNIFAC[er_UNIFAC > bin_edges[-1]] = bin_edges[-1]\n",
    "\n",
    "fig, ax = plt.subplots(2, figsize=(10, 10))\n",
    "\n",
    "path = '/home/garren/Documents/MEng/Code/Latest_results/HPC Files/Hybrid PMF/Subsets/all/Error_plots/Training'\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Plot histograms with the same bin edges\n",
    "ax[0].hist(er_MC_c_0, bins=bin_edges, color='b', alpha=0.5, label='MC - No clusters')\n",
    "ax[0].hist(er_MC_c_1, bins=bin_edges, color='r', alpha=0.5, label='MC - With clusters')\n",
    "ax[0].hist(er_UNIFAC, bins=bin_edges, color='g', alpha=0.5, label='UNIFAC')\n",
    "ax[0].legend(loc='upper right', bbox_to_anchor=(1.3, 1))\n",
    "ax[0].set_ylabel('Frequency')\n",
    "ax[0].set_xlabel('Absolute error')\n",
    "ax[0].set_xticks(ticks=[0, 200, 400, 600, 800, 1000], labels=['0', '200', '400', '600', '800', '1000+'])\n",
    "\n",
    "ax[1].plot(rec_dict_c_0['y_MC'], rec_dict_c_0['y_exp'], '.b', label='MC - No clusters', alpha=0.5)\n",
    "ax[1].plot(rec_dict_c_1['y_MC'], rec_dict_c_1['y_exp'], '.r', label='MC - With clusters', alpha=0.5)\n",
    "ax[1].plot(rec_dict_c_0['y_UNIFAC'], rec_dict_c_0['y_exp'], '.g', label='UNIFAC', alpha=0.5)\n",
    "ax[1].legend(loc='upper right', bbox_to_anchor=(1.3, 1))\n",
    "ax[1].set_ylabel('Experimental')\n",
    "ax[1].set_xlabel('Predicted')\n",
    "max_lim = max(max(rec_dict_c_0['y_exp']), max(rec_dict_c_0['y_MC']), max(rec_dict_c_1['y_MC']), max(rec_dict_c_0['y_UNIFAC']))\n",
    "min_lim = min(min(rec_dict_c_0['y_exp']), min(rec_dict_c_0['y_MC']), min(rec_dict_c_1['y_MC']), min(rec_dict_c_0['y_UNIFAC']))\n",
    "ax[1].plot([min_lim, max_lim], [min_lim, max_lim], 'k--')\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(f'{path}/Err_dist.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the 2D plots for the experimental data - testing (some plots should be here)\n",
    "excel_UNI_plot = '/home/garren/Documents/MEng/Code/Latest_results/HPC Files/UNIFAC_Plots.xlsx'\n",
    "path = f'{post_obj.init_path}/{functional_groups[0]}'\n",
    "for func in functional_groups[1:]:\n",
    "    path += f'_{func}'\n",
    "path += '/2D_plots/Testing'\n",
    "\n",
    "excel_UNI_sheet = 'Testing_Plots'\n",
    "_, Idx_known = post_obj.get_excess_enthalpy()\n",
    "try:\n",
    "    os.makedirs(path)\n",
    "except:\n",
    "    print(f'Directory {path} already exists')\n",
    "\n",
    "all_mix = np.char.add(np.char.add(data_dict_c_0['c1'].astype(str), ' + '), data_dict_c_0['c2'].astype(str))\n",
    "unique_mix, idx = np.unique(all_mix, return_index=True)\n",
    "unique_mix = unique_mix[np.argsort(idx)]\n",
    "\n",
    "df_UNIFAC = pd.read_excel(excel_UNI_plot, sheet_name=excel_UNI_sheet)\n",
    "\n",
    "exp_mix = np.char.add(np.char.add(data_dict_c_0['c1'], ' + '), data_dict_c_0['c2'])\n",
    "UNIFAC_mix = np.char.add(np.char.add(df_UNIFAC['Component 1'].to_numpy().astype(str), ' + '), df_UNIFAC['Component 2'].to_numpy().astype(str))\n",
    "\n",
    "for j in range(len(unique_mix)):\n",
    "    y_idx = exp_mix == unique_mix[j]\n",
    "    UNIFAC_idx = UNIFAC_mix == unique_mix[j]\n",
    "    yy = data_dict_c_0['y_exp'][y_idx]\n",
    "    yy_UNIFAC = df_UNIFAC['UNIFAC_DMD [J/mol]'].to_numpy().astype(float)[UNIFAC_idx]\n",
    "    x_y = data_dict_c_0['x'][y_idx]\n",
    "    T_y = data_dict_c_0['T'][y_idx]\n",
    "    c1 = data_dict_c_0['c1'][y_idx][0]\n",
    "    c2 = data_dict_c_0['c2'][y_idx][0]\n",
    "\n",
    "    x_UNIFAC = df_UNIFAC['Composition component 1 [mol/mol]'].to_numpy().astype(float)[UNIFAC_idx]\n",
    "    T_UNIFAC = df_UNIFAC['Temperature [K]'].to_numpy().astype(float)[UNIFAC_idx]\n",
    "\n",
    "    p12_c_0 = A_c_0[:, Idx_known[j,0], Idx_known[j,1]] * np.array(json.load(open(post_obj.data_file, 'r'))['scaling'])\n",
    "    p21_c_0 = A_c_0[:, Idx_known[j,1], Idx_known[j,0]] * np.array(json.load(open(post_obj.data_file, 'r'))['scaling'])\n",
    "    yy_MC_mean_c_0 = post_obj.excess_enthalpy_predictions(x=x_UNIFAC, T=T_UNIFAC, p12=p12_c_0, p21=p21_c_0)\n",
    "\n",
    "    p12_c_1 = A_c_1[:, Idx_known[j,0], Idx_known[j,1]] * np.array(json.load(open(post_obj.data_file, 'r'))['scaling'])\n",
    "    p21_c_1 = A_c_1[:, Idx_known[j,1], Idx_known[j,0]] * np.array(json.load(open(post_obj.data_file, 'r'))['scaling'])\n",
    "    yy_MC_mean_c_1 = post_obj.excess_enthalpy_predictions(x=x_UNIFAC, T=T_UNIFAC, p12=p12_c_1, p21=p21_c_1)\n",
    "\n",
    "    T_uniq = np.unique(T_UNIFAC)\n",
    "    for i in range(len(T_uniq)):\n",
    "        if not os.path.exists(f'{path}/{j}_{i}.png'):\n",
    "            print(f'{j+1} out of {len(unique_mix)} mixtures')\n",
    "            print(f'{i+1} out of {len(T_uniq)} temperatures')\n",
    "            TT = T_uniq[i]\n",
    "            T_y_idx = np.abs(T_y - TT) <= 0.5\n",
    "            T_UNIFAC_idx = T_UNIFAC == TT\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(x_UNIFAC[T_UNIFAC_idx], yy_UNIFAC[T_UNIFAC_idx], '-g', label='UNIFAC')\n",
    "            ax.plot(x_UNIFAC[T_UNIFAC_idx], yy_MC_mean_c_0[T_UNIFAC_idx], '-b', label='Mean MC - No clusters')\n",
    "            ax.plot(x_UNIFAC[T_UNIFAC_idx], yy_MC_mean_c_1[T_UNIFAC_idx], '-r', label='Mean MC - With clusters')\n",
    "            ax.plot(x_y[T_y_idx], yy[T_y_idx], '.k', label='Experimental Data')\n",
    "            ax.set_xlabel('Composition of Compound 1 [mol/mol]')\n",
    "            ax.set_ylabel('Excess Enthalpy [J/mol]')\n",
    "            ax.set_title(f'(1) {c1} + (2) {c2} at {T_uniq[i]:.2f} K')\n",
    "            ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "            plt.tight_layout()\n",
    "\n",
    "            fig.savefig(f'{path}/{j}_{i}.png', dpi=300)\n",
    "            plt.close(fig)\n",
    "            clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the 3D plots for the experimental data - testing\n",
    "excel_UNI_plot = '/home/garren/Documents/MEng/Code/Latest_results/HPC Files/UNIFAC_Plots.xlsx'\n",
    "path = f'{post_obj.init_path}/{functional_groups[0]}'\n",
    "for func in functional_groups[1:]:\n",
    "    path += f'_{func}'\n",
    "path += '/3D_plots/Testing'\n",
    "\n",
    "excel_UNI_sheet = 'Testing_Plots'\n",
    "_, Idx_known = post_obj.get_excess_enthalpy()\n",
    "try:\n",
    "    os.makedirs(path)\n",
    "except:\n",
    "    print(f'Directory {path} already exists')\n",
    "\n",
    "all_mix = np.char.add(np.char.add(data_dict_c_0['c1'].astype(str), ' + '), data_dict_c_0['c2'].astype(str))\n",
    "unique_mix, idx = np.unique(all_mix, return_index=True)\n",
    "unique_mix = unique_mix[np.argsort(idx)]\n",
    "\n",
    "df_UNIFAC = pd.read_excel(excel_UNI_plot, sheet_name=excel_UNI_sheet)\n",
    "\n",
    "exp_mix = np.char.add(np.char.add(data_dict_c_0['c1'], ' + '), data_dict_c_0['c2'])\n",
    "UNIFAC_mix = np.char.add(np.char.add(df_UNIFAC['Component 1'].to_numpy().astype(str), ' + '), df_UNIFAC['Component 2'].to_numpy().astype(str))\n",
    "\n",
    "for j in range(len(unique_mix)):\n",
    "    if not os.path.exists(f'{path}/{j}.png'):\n",
    "        print(f'{j+1} out of {len(unique_mix)} mixtures')\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        y_idx = exp_mix == unique_mix[j]\n",
    "        UNIFAC_idx = UNIFAC_mix == unique_mix[j]\n",
    "        yy = data_dict_c_0['y_exp'][y_idx]\n",
    "        yy_UNIFAC = df_UNIFAC['UNIFAC_DMD [J/mol]'].to_numpy().astype(float)[UNIFAC_idx]\n",
    "        x_y = data_dict_c_0['x'][y_idx]\n",
    "        T_y = data_dict_c_0['T'][y_idx]\n",
    "        c1 = data_dict_c_0['c1'][y_idx][0]\n",
    "        c2 = data_dict_c_0['c2'][y_idx][0]\n",
    "\n",
    "        x_UNIFAC = df_UNIFAC['Composition component 1 [mol/mol]'].to_numpy().astype(float)[UNIFAC_idx]\n",
    "        T_UNIFAC = df_UNIFAC['Temperature [K]'].to_numpy().astype(float)[UNIFAC_idx]\n",
    "\n",
    "        p12_c_0 = A_c_0[:, Idx_known[j,0], Idx_known[j,1]] * np.array(json.load(open(post_obj.data_file, 'r'))['scaling'])\n",
    "        p21_c_0 = A_c_0[:, Idx_known[j,1], Idx_known[j,0]] * np.array(json.load(open(post_obj.data_file, 'r'))['scaling'])\n",
    "        yy_MC_mean_c_0 = post_obj.excess_enthalpy_predictions(x=x_UNIFAC, T=T_UNIFAC, p12=p12_c_0, p21=p21_c_0)\n",
    "\n",
    "        p12_c_1 = A_c_1[:, Idx_known[j,0], Idx_known[j,1]] * np.array(json.load(open(post_obj.data_file, 'r'))['scaling'])\n",
    "        p21_c_1 = A_c_1[:, Idx_known[j,1], Idx_known[j,0]] * np.array(json.load(open(post_obj.data_file, 'r'))['scaling'])\n",
    "        yy_MC_mean_c_1 = post_obj.excess_enthalpy_predictions(x=x_UNIFAC, T=T_UNIFAC, p12=p12_c_1, p21=p21_c_1)\n",
    "\n",
    "        T_uniq = np.unique(T_UNIFAC)\n",
    "        for i in range(len(T_uniq)):\n",
    "            # Plot median prediction\n",
    "            TT = T_uniq[i]\n",
    "            T_y_idx = np.abs(T_y - TT) <= 0.5\n",
    "            T_UNIFAC_idx = T_UNIFAC == TT\n",
    "            if j == 0:\n",
    "                ax.plot(x_UNIFAC[T_UNIFAC_idx], T_UNIFAC[T_UNIFAC_idx], yy_MC_mean_c_0[T_UNIFAC_idx], c='b', label='Mean MC - No clusters')\n",
    "                ax.plot(x_UNIFAC[T_UNIFAC_idx], T_UNIFAC[T_UNIFAC_idx], yy_MC_mean_c_1[T_UNIFAC_idx], c='r', label='Mean MC - With clusters')\n",
    "            else:\n",
    "                ax.plot(x_UNIFAC[T_UNIFAC_idx], T_UNIFAC[T_UNIFAC_idx], yy_MC_mean_c_0[T_UNIFAC_idx], c='b')\n",
    "                ax.plot(x_UNIFAC[T_UNIFAC_idx], T_UNIFAC[T_UNIFAC_idx], yy_MC_mean_c_1[T_UNIFAC_idx], c='r')\n",
    "            ax.plot(x_UNIFAC[T_UNIFAC_idx], T_UNIFAC[T_UNIFAC_idx], yy_UNIFAC[T_UNIFAC_idx], c='g', label='UNIFAC')\n",
    "\n",
    "        # Scatter plot for experimental data\n",
    "        ax.scatter(x_y, T_y, yy, c='k', marker='.', s=100, label='Experimental Data')\n",
    "\n",
    "        # Custom legend\n",
    "        custom_lines = [\n",
    "            Line2D([0], [0], color='k', marker='.', linestyle='None', markersize=10),  # Experimental Data\n",
    "            Line2D([0], [0], color='g', lw=4),  # UNIFAC\n",
    "            Line2D([0], [0], color='b', lw=4), # Mean MC\n",
    "            Line2D([0], [0], color='r', lw=4)\n",
    "        ]\n",
    "\n",
    "        ax.legend(custom_lines, ['Experimental', 'UNIFAC', 'MC - No cluster', 'MC - With clusters'], loc='upper left', bbox_to_anchor=(1.03, 1))\n",
    "\n",
    "        ax.set_xlabel('Composition of component 1 [mol//mol]', fontsize=14)\n",
    "        ax.set_ylabel('Temperature [K]', fontsize=14)\n",
    "        ax.set_zlabel('Excess Enthalpy [J/mol]', fontsize=14, labelpad=10)\n",
    "        ax.set_title(f'(1) {c1} + (2) {c2}', fontsize=20)\n",
    "        plt.tight_layout()  # Adjust layout to make room for the legend\n",
    "\n",
    "        # Disable offset for all axes\n",
    "        ax.get_xaxis().get_major_formatter().set_useOffset(False)\n",
    "        ax.get_yaxis().get_major_formatter().set_useOffset(False)\n",
    "        ax.get_zaxis().get_major_formatter().set_useOffset(False)\n",
    "\n",
    "        plt.savefig(f'{path}/{j}.png', dpi=300)\n",
    "\n",
    "        plt.close(fig)\n",
    "        clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the 2D plots for the experimental data - training (some plots should be here)\n",
    "excel_UNI_plot = '/home/garren/Documents/MEng/Code/Latest_results/HPC Files/UNIFAC_Plots.xlsx'\n",
    "path = f'{post_obj.init_path}/{functional_groups[0]}'\n",
    "for func in functional_groups[1:]:\n",
    "    path += f'_{func}'\n",
    "path += '/2D_plots/Training'\n",
    "excel_UNI_sheet = 'Training_Plots'\n",
    "Idx_known = np.array(json.load(open(post_obj.data_file, 'r'))['Idx_known']) - 1\n",
    "try:\n",
    "    os.makedirs(path)\n",
    "except:\n",
    "    print(f'Directory {path} already exists')\n",
    "    \n",
    "all_mix = np.char.add(np.char.add(rec_dict_c_0['c1'].astype(str), ' + '), rec_dict_c_0['c2'].astype(str))\n",
    "unique_mix, idx = np.unique(all_mix, return_index=True)\n",
    "unique_mix = unique_mix[np.argsort(idx)]\n",
    "\n",
    "df_UNIFAC = pd.read_excel(excel_UNI_plot, sheet_name=excel_UNI_sheet)\n",
    "\n",
    "exp_mix = np.char.add(np.char.add(rec_dict_c_0['c1'], ' + '), rec_dict_c_0['c2'])\n",
    "UNIFAC_mix = np.char.add(np.char.add(df_UNIFAC['Component 1'].to_numpy().astype(str), ' + '), df_UNIFAC['Component 2'].to_numpy().astype(str))\n",
    "\n",
    "for j in range(len(unique_mix)):\n",
    "    y_idx = exp_mix == unique_mix[j]\n",
    "    UNIFAC_idx = UNIFAC_mix == unique_mix[j]\n",
    "    yy = rec_dict_c_0['y_exp'][y_idx]\n",
    "    yy_UNIFAC = df_UNIFAC['UNIFAC_DMD [J/mol]'].to_numpy().astype(float)[UNIFAC_idx]\n",
    "    x_y = rec_dict_c_0['x'][y_idx]\n",
    "    T_y = rec_dict_c_0['T'][y_idx]\n",
    "    c1 = rec_dict_c_0['c1'][y_idx][0]\n",
    "    c2 = rec_dict_c_0['c2'][y_idx][0]\n",
    "\n",
    "    x_UNIFAC = df_UNIFAC['Composition component 1 [mol/mol]'].to_numpy().astype(float)[UNIFAC_idx]\n",
    "    T_UNIFAC = df_UNIFAC['Temperature [K]'].to_numpy().astype(float)[UNIFAC_idx]\n",
    "\n",
    "    p12_c_0 = A_c_0[:, Idx_known[j,0], Idx_known[j,1]] * np.array(json.load(open(post_obj.data_file, 'r'))['scaling'])\n",
    "    p21_c_0 = A_c_0[:, Idx_known[j,1], Idx_known[j,0]] * np.array(json.load(open(post_obj.data_file, 'r'))['scaling'])\n",
    "    yy_MC_mean_c_0 = post_obj.excess_enthalpy_predictions(x=x_UNIFAC, T=T_UNIFAC, p12=p12_c_0, p21=p21_c_0)\n",
    "\n",
    "    p12_c_1 = A_c_1[:, Idx_known[j,0], Idx_known[j,1]] * np.array(json.load(open(post_obj.data_file, 'r'))['scaling'])\n",
    "    p21_c_1 = A_c_1[:, Idx_known[j,1], Idx_known[j,0]] * np.array(json.load(open(post_obj.data_file, 'r'))['scaling'])\n",
    "    yy_MC_mean_c_1 = post_obj.excess_enthalpy_predictions(x=x_UNIFAC, T=T_UNIFAC, p12=p12_c_1, p21=p21_c_1)\n",
    "\n",
    "    T_uniq = np.unique(T_UNIFAC)\n",
    "    for i in range(len(T_uniq)):\n",
    "        if not os.path.exists(f'{path}/{j}_{i}.png'):\n",
    "            print(f'{j+1} out of {len(unique_mix)} mixtures')\n",
    "            print(f'{i+1} out of {len(T_uniq)} temperatures')\n",
    "            TT = T_uniq[i]\n",
    "            T_y_idx = np.abs(T_y - TT) <= 0.5\n",
    "            T_UNIFAC_idx = T_UNIFAC == TT\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(x_UNIFAC[T_UNIFAC_idx], yy_UNIFAC[T_UNIFAC_idx], '-g', label='UNIFAC')\n",
    "            ax.plot(x_UNIFAC[T_UNIFAC_idx], yy_MC_mean_c_0[T_UNIFAC_idx], '-b', label='Mean MC - No clusters')\n",
    "            ax.plot(x_UNIFAC[T_UNIFAC_idx], yy_MC_mean_c_1[T_UNIFAC_idx], '-r', label='Mean MC - With clusters')\n",
    "            ax.plot(x_y[T_y_idx], yy[T_y_idx], '.k', label='Experimental Data')\n",
    "            ax.set_xlabel('Composition of Compound 1 [mol/mol]')\n",
    "            ax.set_ylabel('Excess Enthalpy [J/mol]')\n",
    "            ax.set_title(f'(1) {c1} + (2) {c2} at {T_uniq[i]:.2f} K')\n",
    "            ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "            plt.tight_layout()\n",
    "\n",
    "            fig.savefig(f'{path}/{j}_{i}.png', dpi=300)\n",
    "            plt.close(fig)\n",
    "            clear_output(wait=False)\n",
    "\n",
    "            try:\n",
    "                del fig\n",
    "            except:\n",
    "                continue\n",
    "            del ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the 3D plots for the experimental data - training\n",
    "excel_UNI_plot = '/home/garren/Documents/MEng/Code/Latest_results/HPC Files/UNIFAC_Plots.xlsx'\n",
    "path = f'{post_obj.init_path}/{functional_groups[0]}'\n",
    "for func in functional_groups[1:]:\n",
    "    path += f'_{func}'\n",
    "path += '/3D_plots/Training'\n",
    "\n",
    "excel_UNI_sheet = 'Training_Plots'\n",
    "Idx_known = np.array(json.load(open(post_obj.data_file, 'r'))['Idx_known']) - 1\n",
    "try:\n",
    "    os.makedirs(path)\n",
    "except:\n",
    "    print(f'Directory {path} already exists')\n",
    "\n",
    "all_mix = np.char.add(np.char.add(rec_dict_c_0['c1'].astype(str), ' + '), rec_dict_c_0['c2'].astype(str))\n",
    "unique_mix, idx = np.unique(all_mix, return_index=True)\n",
    "unique_mix = unique_mix[np.argsort(idx)]\n",
    "\n",
    "df_UNIFAC = pd.read_excel(excel_UNI_plot, sheet_name=excel_UNI_sheet)\n",
    "\n",
    "exp_mix = np.char.add(np.char.add(rec_dict_c_0['c1'], ' + '), rec_dict_c_0['c2'])\n",
    "UNIFAC_mix = np.char.add(np.char.add(df_UNIFAC['Component 1'].to_numpy().astype(str), ' + '), df_UNIFAC['Component 2'].to_numpy().astype(str))\n",
    "\n",
    "for j in range(len(unique_mix)):\n",
    "    if not os.path.exists(f'{path}/{j}.png'):\n",
    "        print(f'{j+1} out of {len(unique_mix)} mixtures')\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        y_idx = exp_mix == unique_mix[j]\n",
    "        UNIFAC_idx = UNIFAC_mix == unique_mix[j]\n",
    "        yy = rec_dict_c_0['y_exp'][y_idx]\n",
    "        yy_UNIFAC = df_UNIFAC['UNIFAC_DMD [J/mol]'].to_numpy().astype(float)[UNIFAC_idx]\n",
    "        x_y = rec_dict_c_0['x'][y_idx]\n",
    "        T_y = rec_dict_c_0['T'][y_idx]\n",
    "        c1 = rec_dict_c_0['c1'][y_idx][0]\n",
    "        c2 = rec_dict_c_0['c2'][y_idx][0]\n",
    "\n",
    "        x_UNIFAC = df_UNIFAC['Composition component 1 [mol/mol]'].to_numpy().astype(float)[UNIFAC_idx]\n",
    "        T_UNIFAC = df_UNIFAC['Temperature [K]'].to_numpy().astype(float)[UNIFAC_idx]\n",
    "\n",
    "        p12_c_0 = A_c_0[:, Idx_known[j,0], Idx_known[j,1]] * np.array(json.load(open(post_obj.data_file, 'r'))['scaling'])\n",
    "        p21_c_0 = A_c_0[:, Idx_known[j,1], Idx_known[j,0]] * np.array(json.load(open(post_obj.data_file, 'r'))['scaling'])\n",
    "        yy_MC_mean_c_0 = post_obj.excess_enthalpy_predictions(x=x_UNIFAC, T=T_UNIFAC, p12=p12_c_0, p21=p21_c_0)\n",
    "\n",
    "        p12_c_1 = A_c_1[:, Idx_known[j,0], Idx_known[j,1]] * np.array(json.load(open(post_obj.data_file, 'r'))['scaling'])\n",
    "        p21_c_1 = A_c_1[:, Idx_known[j,1], Idx_known[j,0]] * np.array(json.load(open(post_obj.data_file, 'r'))['scaling'])\n",
    "        yy_MC_mean_c_1 = post_obj.excess_enthalpy_predictions(x=x_UNIFAC, T=T_UNIFAC, p12=p12_c_1, p21=p21_c_1)\n",
    "\n",
    "        T_uniq = np.unique(T_UNIFAC)\n",
    "        for i in range(len(T_uniq)):\n",
    "            # Plot median prediction\n",
    "            TT = T_uniq[i]\n",
    "            T_y_idx = np.abs(T_y - TT) <= 0.5\n",
    "            T_UNIFAC_idx = T_UNIFAC == TT\n",
    "            if j == 0:\n",
    "                ax.plot(x_UNIFAC[T_UNIFAC_idx], T_UNIFAC[T_UNIFAC_idx], yy_MC_mean_c_0[T_UNIFAC_idx], c='b', label='Mean MC - No clusters')\n",
    "                ax.plot(x_UNIFAC[T_UNIFAC_idx], T_UNIFAC[T_UNIFAC_idx], yy_MC_mean_c_1[T_UNIFAC_idx], c='r', label='Mean MC - With clusters')\n",
    "            else:\n",
    "                ax.plot(x_UNIFAC[T_UNIFAC_idx], T_UNIFAC[T_UNIFAC_idx], yy_MC_mean_c_0[T_UNIFAC_idx], c='b')\n",
    "                ax.plot(x_UNIFAC[T_UNIFAC_idx], T_UNIFAC[T_UNIFAC_idx], yy_MC_mean_c_1[T_UNIFAC_idx], c='r')\n",
    "            ax.plot(x_UNIFAC[T_UNIFAC_idx], T_UNIFAC[T_UNIFAC_idx], yy_UNIFAC[T_UNIFAC_idx], c='g', label='UNIFAC')\n",
    "\n",
    "        # Scatter plot for experimental data\n",
    "        ax.scatter(x_y, T_y, yy, c='k', marker='.', s=100, label='Experimental Data')\n",
    "\n",
    "        # Custom legend\n",
    "        custom_lines = [\n",
    "            Line2D([0], [0], color='k', marker='.', linestyle='None', markersize=10),  # Experimental Data\n",
    "            Line2D([0], [0], color='g', lw=4),  # UNIFAC\n",
    "            Line2D([0], [0], color='b', lw=4), # Mean MC\n",
    "            Line2D([0], [0], color='r', lw=4)\n",
    "        ]\n",
    "\n",
    "        ax.legend(custom_lines, ['Experimental', 'UNIFAC', 'MC - No cluster', 'MC - With clusters'], loc='upper left', bbox_to_anchor=(1.03, 1))\n",
    "\n",
    "        ax.set_xlabel('Composition of component 1 [mol//mol]', fontsize=14)\n",
    "        ax.set_ylabel('Temperature [K]', fontsize=14)\n",
    "        ax.set_zlabel('Excess Enthalpy [J/mol]', fontsize=14, labelpad=10)\n",
    "        ax.set_title(f'(1) {c1} + (2) {c2}', fontsize=20)\n",
    "        plt.tight_layout()  # Adjust layout to make room for the legend\n",
    "\n",
    "        # Disable offset for all axes\n",
    "        ax.get_xaxis().get_major_formatter().set_useOffset(False)\n",
    "        ax.get_yaxis().get_major_formatter().set_useOffset(False)\n",
    "        ax.get_zaxis().get_major_formatter().set_useOffset(False)\n",
    "\n",
    "        plt.savefig(f'{path}/{j}.png', dpi=300)\n",
    "\n",
    "        plt.close(fig)\n",
    "        clear_output(wait=False)\n",
    "\n",
    "        try: \n",
    "            del fig\n",
    "        except:\n",
    "            continue\n",
    "        del ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save error metrics to excel File\n",
    "# get testing error metrics\n",
    "all_err_metrics = err_metrics_c_0.copy()\n",
    "all_cols = all_err_metrics.columns.to_list()\n",
    "apppend_cols = []\n",
    "for i in range(len(all_cols)):\n",
    "    if all_cols[i][0] == 'MC':\n",
    "        t = all_cols[i][1]\n",
    "        all_cols[i] = ('MC - No Cluster', t)\n",
    "        apppend_cols += [('MC - With Cluster', t)]\n",
    "all_err_metrics.columns = pd.MultiIndex.from_tuples(all_cols)\n",
    "all_err_metrics = pd.concat([all_err_metrics,  pd.DataFrame({apppend_cols[i]: err_metrics_c_1.iloc[:,-3:].to_numpy()[:,i] for i in range(3)})], axis=1)\n",
    "\n",
    "# get training error metrics\n",
    "all_rec_err_metrics = rec_err_metrics_c_0.copy()\n",
    "all_cols = all_rec_err_metrics.columns.to_list()\n",
    "apppend_cols = []\n",
    "for i in range(len(all_cols)):\n",
    "    if all_cols[i][0] == 'MC':\n",
    "        t = all_cols[i][1]\n",
    "        all_cols[i] = ('MC - No Cluster', t)\n",
    "        apppend_cols += [('MC - With Cluster', t)]\n",
    "all_rec_err_metrics.columns = pd.MultiIndex.from_tuples(all_cols)\n",
    "all_rec_err_metrics = pd.concat([all_rec_err_metrics,  pd.DataFrame({apppend_cols[i]: rec_err_metrics_c_1.iloc[:,-2:].to_numpy()[:,i] for i in range(2)})], axis=1)\n",
    "\n",
    "# save to excel file\n",
    "write_path = f'{post_obj.init_path}/{functional_groups[0]}'\n",
    "for func in functional_groups[1:]:\n",
    "    write_path += f'_{func}'\n",
    "write_path += '/Errors_Metrics.xlsx'\n",
    "with pd.ExcelWriter(write_path) as writer:\n",
    "    all_err_metrics.to_excel(writer, sheet_name='Testing')\n",
    "\n",
    "    all_rec_err_metrics.to_excel(writer, sheet_name='Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39440/214037210.py:72: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  all_dfs[i][all_dfs[i].isna()] = ''\n",
      "/tmp/ipykernel_39440/214037210.py:72: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  all_dfs[i][all_dfs[i].isna()] = ''\n",
      "/tmp/ipykernel_39440/214037210.py:72: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  all_dfs[i][all_dfs[i].isna()] = ''\n",
      "/tmp/ipykernel_39440/214037210.py:72: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  all_dfs[i][all_dfs[i].isna()] = ''\n",
      "/tmp/ipykernel_39440/214037210.py:72: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  all_dfs[i][all_dfs[i].isna()] = ''\n",
      "/tmp/ipykernel_39440/214037210.py:72: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  all_dfs[i][all_dfs[i].isna()] = ''\n",
      "/tmp/ipykernel_39440/214037210.py:72: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  all_dfs[i][all_dfs[i].isna()] = ''\n",
      "/tmp/ipykernel_39440/214037210.py:72: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  all_dfs[i][all_dfs[i].isna()] = ''\n",
      "/tmp/ipykernel_39440/214037210.py:72: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  all_dfs[i][all_dfs[i].isna()] = ''\n",
      "/tmp/ipykernel_39440/214037210.py:72: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  all_dfs[i][all_dfs[i].isna()] = ''\n",
      "/tmp/ipykernel_39440/214037210.py:72: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  all_dfs[i][all_dfs[i].isna()] = ''\n",
      "/tmp/ipykernel_39440/214037210.py:72: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  all_dfs[i][all_dfs[i].isna()] = ''\n",
      "/tmp/ipykernel_39440/214037210.py:72: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  all_dfs[i][all_dfs[i].isna()] = ''\n",
      "/tmp/ipykernel_39440/214037210.py:72: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  all_dfs[i][all_dfs[i].isna()] = ''\n",
      "/tmp/ipykernel_39440/214037210.py:72: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  all_dfs[i][all_dfs[i].isna()] = ''\n"
     ]
    }
   ],
   "source": [
    "## save sparsity matrix and visualization wrt to spartsity to excel\n",
    "idx1_test = np.sum((err_metrics_c_0['IUPAC', 'Component 1'][:-1].to_numpy().astype(str)[:, np.newaxis] == post_obj.c_all[np.newaxis,:])*np.arange(post_obj.c_all.shape[0]), axis=1)\n",
    "idx2_test = np.sum((err_metrics_c_0['IUPAC', 'Component 2'][:-1].to_numpy().astype(str)[:, np.newaxis] == post_obj.c_all[np.newaxis,:])*np.arange(post_obj.c_all.shape[0]), axis=1)\n",
    "\n",
    "idx1_train = np.sum((rec_err_metrics_c_0['IUPAC', 'Component 1'][:-1].to_numpy().astype(str)[:, np.newaxis] == post_obj.c_all[np.newaxis,:])*np.arange(post_obj.c_all.shape[0]), axis=1)\n",
    "idx2_train = np.sum((rec_err_metrics_c_0['IUPAC', 'Component 2'][:-1].to_numpy().astype(str)[:, np.newaxis] == post_obj.c_all[np.newaxis,:])*np.arange(post_obj.c_all.shape[0]), axis=1)\n",
    "\n",
    "# name of sheets\n",
    "sheet_names = ['Sparsity Marix', 'MAE - Test (UNI)', 'RMSE - Test (UNI)', 'MARE - Test (UNI)', 'MAE - Train (UNI)', 'RMSE - Train(UNI)', 'MAE - Test (c=0)', 'RMSE - Test (c=0)', 'MARE - Test (c=0)', 'MAE - Train (c=0)', 'RMSE - Train (c=0)', 'MAE - Test (c=1)', 'RMSE - Test (c=1)', 'MARE - Test (c=1)', 'MAE - Train (c=1)', 'RMSE - Train (c=1)']\n",
    "\n",
    "# create list of data frames\n",
    "all_dfs = []\n",
    "\n",
    "all_dfs += [np.zeros((post_obj.c_all.shape[0], post_obj.c_all.shape[0])).astype(int)]\n",
    "all_dfs[0][idx1_train, idx2_train] = 1\n",
    "all_dfs[0] = pd.DataFrame(all_dfs[0], index=post_obj.c_all, columns=post_obj.c_all)\n",
    "\n",
    "# name of sheets\n",
    "list_to_parse = ['' for j in range(len(sheet_names))]\n",
    "\n",
    "for i in range(1, len(sheet_names)):\n",
    "    sheet_name = sheet_names[i]\n",
    "    # assign corresponding UNIFAC\n",
    "    if \"UNI\" in sheet_name:\n",
    "        if \"Test\" in sheet_name:\n",
    "            if \"MAE\" in sheet_name:\n",
    "                list_to_parse[i] = err_metrics_c_0['UNIFAC', 'MAE'][:-1].to_numpy()\n",
    "            elif \"RMSE\" in sheet_name:\n",
    "                list_to_parse[i] = err_metrics_c_0['UNIFAC', 'RMSE'][:-1].to_numpy()\n",
    "            elif \"MARE\" in sheet_name:\n",
    "                list_to_parse[i] = err_metrics_c_0['UNIFAC', 'MARE'][:-1].to_numpy()\n",
    "        elif \"Train\" in sheet_name:\n",
    "            if \"MAE\" in sheet_name:\n",
    "                list_to_parse[i] = rec_err_metrics_c_0['UNIFAC', 'MAE'][:-1].to_numpy()\n",
    "            elif \"RMSE\" in sheet_name:\n",
    "                list_to_parse[i] = rec_err_metrics_c_0['UNIFAC', 'RMSE'][:-1].to_numpy()\n",
    "    # assign corresponding c=0\n",
    "    elif \"c=0\" in sheet_name:\n",
    "        if \"Test\" in sheet_name:\n",
    "            if \"MAE\" in sheet_name:\n",
    "                list_to_parse[i] = err_metrics_c_0['MC', 'MAE'][:-1].to_numpy()\n",
    "            elif \"RMSE\" in sheet_name:\n",
    "                list_to_parse[i] = err_metrics_c_0['MC', 'RMSE'][:-1].to_numpy()\n",
    "            elif \"MARE\" in sheet_name:\n",
    "                list_to_parse[i] = err_metrics_c_0['MC', 'MARE'][:-1].to_numpy()\n",
    "        elif \"Train\" in sheet_name:\n",
    "            if \"MAE\" in sheet_name:\n",
    "                list_to_parse[i] = rec_err_metrics_c_0['MC', 'MAE'][:-1].to_numpy()\n",
    "            elif \"RMSE\" in sheet_name:\n",
    "                list_to_parse[i] = rec_err_metrics_c_0['MC', 'RMSE'][:-1].to_numpy()\n",
    "    # assign corresponding c=1\n",
    "    elif \"c=1\" in sheet_name:\n",
    "        if \"Test\" in sheet_name:\n",
    "            if \"MAE\" in sheet_name:\n",
    "                list_to_parse[i] = err_metrics_c_1['MC', 'MAE'][:-1].to_numpy()\n",
    "            elif \"RMSE\" in sheet_name:\n",
    "                list_to_parse[i] = err_metrics_c_1['MC', 'RMSE'][:-1].to_numpy()\n",
    "            elif \"MARE\" in sheet_name:\n",
    "                list_to_parse[i] = err_metrics_c_1['MC', 'MARE'][:-1].to_numpy()\n",
    "        elif \"Train\" in sheet_name:\n",
    "            if \"MAE\" in sheet_name:\n",
    "                list_to_parse[i] = rec_err_metrics_c_1['MC', 'MAE'][:-1].to_numpy()\n",
    "            elif \"RMSE\" in sheet_name:\n",
    "                list_to_parse[i] = rec_err_metrics_c_1['MC', 'RMSE'][:-1].to_numpy()\n",
    "\n",
    "    all_dfs += [np.nan*np.zeros((post_obj.c_all.shape[0], post_obj.c_all.shape[0]))]\n",
    "    if \"Train\" in sheet_name:\n",
    "        all_dfs[i][idx1_train, idx2_train] = list_to_parse[i]\n",
    "    elif \"Test\" in sheet_name:\n",
    "        all_dfs[i][idx1_test, idx2_test] = list_to_parse[i]\n",
    "    all_dfs[i] = pd.DataFrame(all_dfs[i], index=post_obj.c_all, columns=post_obj.c_all)\n",
    "    all_dfs[i][all_dfs[i].isna()] = ''\n",
    "\n",
    "# save to excel file\n",
    "write_path = f'{post_obj.init_path}/{functional_groups[0]}'\n",
    "for func in functional_groups[1:]:\n",
    "    write_path += f'_{func}'\n",
    "write_path += '/Sparsity_Metrics.xlsx'\n",
    "\n",
    "with pd.ExcelWriter(write_path) as writer:\n",
    "    for i in range(len(sheet_names)):\n",
    "        all_dfs[i].to_excel(writer, sheet_name=sheet_names[i], index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/garren/Documents/MEng/Code/Latest_results/HPC Files/Hybrid PMF/Subsets/all/Sparsity_Metrics.xlsx'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmdstan_condaforge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
